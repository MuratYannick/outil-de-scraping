# Changelog - Outil de Scraping

## [Non versionn√©e] - 3 D√©cembre 2025

### ‚ú® Nouvelle Fonctionnalit√© : Interface de Nettoyage des Doublons
**Date** : 3 d√©cembre 2025 (nuit - suite)

**Objectif** : Permettre √† l'utilisateur de nettoyer les doublons directement depuis l'interface web.

**Fonctionnalit√©s ajout√©es** :

1. **API Backend** :
   - Route `GET /api/prospects/duplicates/detect` - D√©tecte les doublons
   - Route `POST /api/prospects/duplicates/clean` - Fusionne les doublons
   - Service `duplicateCleanerService.js` - Logique r√©utilisable extraite du script CLI

2. **Interface Frontend** :
   - Composant `DuplicateCleanerButton.jsx` - Bouton avec modal de confirmation
   - Modal d'affichage des doublons d√©tect√©s avec comparaison visuelle
   - Int√©gration dans la barre d'actions de la page Prospects
   - Rafra√Æchissement automatique apr√®s nettoyage

3. **Fonctionnement** :
   - Clic sur "Nettoyer les doublons" ‚Üí D√©tection en cours
   - Affichage d'un modal listant tous les doublons avec d√©tails
   - Confirmation requise avant fusion
   - Fusion avec indicateur de progression
   - Message de succ√®s avec statistiques

**Fichiers cr√©√©s** :
- `backend/src/services/duplicateCleanerService.js` - Service de d√©tection et fusion
- `frontend/src/components/DuplicateCleanerButton.jsx` - Composant React du bouton

**Fichiers modifi√©s** :
- `backend/src/controllers/prospectController.js` - Ajout des contr√¥leurs d'API
- `backend/src/routes/prospectRoutes.js` - Ajout des routes
- `frontend/src/services/api.js` - Ajout des appels API
- `frontend/src/App.jsx` - Int√©gration du bouton

**Avantages** :
- Plus besoin d'utiliser le terminal pour nettoyer les doublons
- Interface visuelle pour voir exactement ce qui sera fusionn√©
- Confirmation interactive avant toute modification
- Retour imm√©diat avec statistiques d√©taill√©es

---

### üîß Am√©lioration : D√©tection de Doublons Plus Stricte
**Date** : 3 d√©cembre 2025 (nuit)

**Objectif** : Affiner la logique de d√©tection pour √©viter les faux positifs.

**Modifications apport√©es** :
1. **Changement du crit√®re obligatoire** : Code postal au lieu de ville
   - Rationale : Plusieurs villes peuvent avoir le m√™me nom
   - Emp√™che les fusions erron√©es entre villes homonymes

2. **Logique combin√©e (AND au lieu de OR)** :
   - **Chemin A** (avec adresses) : Requiert adresse similaire **ET** nom similaire (‚â•85%)
   - **Chemin B** (sans adresse) : Requiert nom similaire (‚â•85%) **ET** au moins un contact identique
   - Emp√™che la fusion de diff√©rentes entreprises dans le m√™me immeuble
   - Emp√™che la fusion de plusieurs agences d'une m√™me entreprise

3. **Am√©lioration de l'algorithme de similarit√© des noms** :
   - Impl√©mentation compl√®te de l'algorithme de Levenshtein (matrice)
   - Normalisation avanc√©e : suppression accents, apostrophes, tirets
   - D√©tection des noms contenus dans d'autres (ex: "L'Entr Potes" ‚äÇ "L'ENTR'potes - Restaurant")
   - Comparaison bas√©e sur les mots (ordre diff√©rent acceptable)
   - Similarit√© par intersection de mots (‚â•65% de mots en commun)

4. **Fichiers modifi√©s** :
   - `backend/scripts/clean-merge-duplicates.js` - Logique de d√©tection affin√©e
   - `CLEAN_MERGE.md` - Documentation mise √† jour avec exemples de non-doublons
   - `backend/scripts/test-duplicate-detection-logic.js` - Suite de tests compl√®te (10 tests)

**R√©sultats des tests** :
- ‚úÖ 10/10 tests passent (100%)
- D√©tecte correctement le cas "L'Entr Potes"
- √âvite les faux positifs (entreprises diff√©rentes, agences multiples)

---

### ‚ú® Nouvelle Fonctionnalit√© : Nettoyage et Fusion des Doublons
**Date** : 3 d√©cembre 2025 (soir)

**Objectif** : Nettoyer la base de donn√©es en d√©tectant et fusionnant intelligemment les prospects en doublon.

**Probl√©matique r√©solue** :
- Un m√™me prospect peut √™tre enregistr√© plusieurs fois avec des variations de nom ou d'adresse
- Exemple : "L'Entr Potes" (Pages Jaunes) vs "L'ENTR'potes - Restaurant - Hy√®res" (Google Maps)
- Donn√©es fragment√©es entre plusieurs enregistrements

**Crit√®res de d√©tection (logique initiale, affin√©e ensuite - voir ci-dessus)** :
1. **Obligatoire** : M√™me code postal (modifi√© de "ville" vers "code postal")
2. **Chemin A** (avec adresses) : Adresse similaire **ET** nom similaire
3. **Chemin B** (sans adresse) : Nom similaire **ET** contact identique

**Strat√©gie de fusion** :
- Conserve le prospect avec le plus de champs remplis
- Fusionne tous les tags des deux prospects
- Fusionne toutes les sources des deux prospects
- Enrichit avec les donn√©es manquantes
- Supprime le doublon

**Fichiers cr√©√©s** :
- `backend/scripts/clean-merge-duplicates.js` - Script principal de nettoyage
- `backend/scripts/test-clean-merge.js` - Script de test avec exemple
- `CLEAN_MERGE.md` - Documentation compl√®te (500+ lignes)

**Commande** :
```bash
npm run db:clean-merge
```

**Fonctionnalit√©s** :
- Groupement par ville pour optimisation
- Algorithme de similarit√© de Levenshtein pour les noms
- Utilisation de l'addressNormalizer pour les adresses
- Transaction atomique par fusion (rollback en cas d'erreur)
- Confirmation interactive avant fusion
- Rapport d√©taill√© des doublons d√©tect√©s
- Statistiques finales

**Exemple de r√©sultat** :
- Avant : 2 prospects ("L'Entr Potes" + "L'ENTR'potes - Restaurant - Hy√®res")
- Apr√®s : 1 prospect avec toutes les donn√©es fusionn√©es (t√©l√©phone + GPS + note + 2 tags + 2 sources)

**Documentation** : Voir [CLEAN_MERGE.md](CLEAN_MERGE.md)

---

### üêõ Correction : Extraction URL site web Pages Jaunes
**Date** : 3 d√©cembre 2025 (soir)

**Probl√®me** : Le scraper Pages Jaunes n'extrayait pas l'URL du site web des entreprises lorsqu'elle √©tait disponible.

**Exemple** : Pour "Caron Plomberie" √† Hy√®res, l'URL `http://www.caronplomberie.fr` n'√©tait pas r√©cup√©r√©e.

**Cause** : Le s√©lecteur cherchait `.bi-website a` alors que la structure HTML utilise `a.bi-website` (le lien a directement la classe).

**Fichier corrig√©** :
- `backend/src/services/scrapers/pagesJaunesScraper.js` :
  - Ajout de `a.bi-website` en premier s√©lecteur (priorit√©)
  - Ajout de `.bi-address a.bi-website` comme alternative
  - Ajout d'un filtre pour exclure les liens internes Pages Jaunes
  - V√©rification que l'URL ne contient pas 'pagesjaunes.fr' et ne commence pas par '#'

**Test** :
- Cr√©ation de `backend/scripts/test-pages-jaunes-website-url.js`
- Test avec l'HTML r√©el de la carte Caron Plomberie
- ‚úÖ Test pass√© : URL correctement extraite

**R√©sultat** : Les URLs des sites web des entreprises sont maintenant correctement r√©cup√©r√©es depuis Pages Jaunes.

---

### üêõ Correction : Scripts db:drop et db:clear
**Date** : 3 d√©cembre 2025 (apr√®s-midi)

**Probl√®me** : Les scripts `npm run db:drop` et `npm run db:clear` ne supprimaient pas les nouvelles tables `prospects_sources` et `sources_scraping`.

**Fichiers corrig√©s** :
- `backend/scripts/drop.js` :
  - Ajout de la suppression de `prospects_sources`
  - Ajout de la suppression de `sources_scraping`
  - Mise √† jour des messages de confirmation
- `backend/scripts/clear.js` :
  - Import de `SourceScraping`
  - Ajout du comptage des sources
  - Ajout du vidage de `prospects_sources`
  - Ajout du vidage de `sources_scraping`

**R√©sultat** : Les commandes `db:drop` et `db:clear` nettoient maintenant correctement toutes les tables du syst√®me.

---

### üî• Am√©lioration Critique : Normalisation d'Adresses
**Date** : 3 d√©cembre 2025 (apr√®s-midi)

**Objectif** : Am√©liorer la d√©tection des doublons en normalisant les adresses avant comparaison.

**Probl√©matique r√©solue** :
- Pages Jaunes utilise des adresses compl√®tes : "84 boulevard Picaud"
- Google Maps utilise des abr√©viations : "84 bd Picaud"
- Avec/sans compl√©ments : "2 rue felix faure" vs "les all√©es 2 rue felix faure"
- ‚Üí Sans normalisation, ces adresses cr√©aient des prospects en double

**Solution impl√©ment√©e** :
- Nouveau fichier utilitaire : `backend/src/utils/addressNormalizer.js`
- Fonction `normalizeAddress()` : 8 √©tapes de normalisation
- Fonction `addressesMatch()` : Comparaison fuzzy avec 70% de similarit√©
- Int√©gration dans `scrapingController.js` pour la d√©tection de doublons

**Traitements de normalisation** :
1. Conversion en minuscules
2. Suppression des accents (NFD normalization)
3. Suppression de la ponctuation (`,`, `.`, `;`, `-`)
4. Remplacement des mots par abr√©viations :
   - `boulevard` ‚Üí `bd`, `avenue` ‚Üí `av`, `rue` ‚Üí `r`
   - `place` ‚Üí `pl`, `cours` ‚Üí `crs`, `all√©e` ‚Üí `all`
   - `saint` ‚Üí `st`, `g√©n√©ral` ‚Üí `gal`, etc.
   - 67 abr√©viations dans le dictionnaire
5. Suppression des compl√©ments (batiment, residence, appartement, etc.)
6. Suppression des articles (`les`, `le`, `la`, `l'`)
7. Nettoyage des espaces multiples
8. Filtrage des mots courts non essentiels

**Fichiers cr√©√©s** :
- `backend/src/utils/addressNormalizer.js` - Utilitaire de normalisation
- `backend/scripts/test-address-normalization.js` - Tests (12 cas, 100% r√©ussis)

**Fichiers modifi√©s** :
- `backend/src/controllers/scrapingController.js` :
  - Import de `addressesMatch()`
  - Fonction `isDuplicate` : Utilise normalisation pour v√©rification en temps r√©el
  - Fonction `saveProspects()` : D√©tection en 2 √©tapes (exact + normalis√©)
  - Logs d√©taill√©s quand doublon d√©tect√© via normalisation

**Tests** :
```bash
node backend/scripts/test-address-normalization.js
# ‚úÖ 12/12 tests pass√©s (100%)
```

**Exemples de doublons maintenant d√©tect√©s** :
- ‚úÖ "84 boulevard Picaud" ‚âà "84 bd Picaud"
- ‚úÖ "2 rue felix faure" ‚âà "les all√©es 2 rue felix faure"
- ‚úÖ "15 Avenue des Champs Elys√©es" ‚âà "15 av des Champs Elys√©es"
- ‚úÖ "10 Place Saint-Michel, Batiment A" ‚âà "10 pl St Michel"

**Documentation mise √† jour** :
- `SOURCES_MULTIPLES.md` : Nouvelle section "Normalisation d'adresses"

---

### üéØ Fonctionnalit√© Majeure : Syst√®me de Sources Multiples

#### Impl√©mentation : Gestion des sources multiples pour les prospects
**Date** : 3 d√©cembre 2025

**Objectif** : Permettre √† un prospect d'avoir plusieurs sources de scraping et tracer l'origine compl√®te des donn√©es.

**Probl√©matique r√©solue** :
- Avant : Un prospect ne pouvait avoir qu'une seule source. Si trouv√© sur plusieurs sources, seule la derni√®re √©tait conserv√©e.
- Apr√®s : Un prospect peut avoir plusieurs sources simultan√©ment. Lors d'un doublon, la nouvelle source est automatiquement ajout√©e sans perdre les sources existantes.

**Architecture Base de Donn√©es** :

1. **Nouvelle table `sources_scraping`** :
   - `id` (PK, AUTO_INCREMENT)
   - `nom` (VARCHAR 100, UNIQUE) - Ex: "Pages Jaunes", "Google Maps"
   - `description` (TEXT)
   - `couleur` (VARCHAR 7) - Code hex pour badges color√©s
   - `actif` (BOOLEAN)
   - `date_creation` (DATETIME)
   - Sources par d√©faut cr√©√©es : Pages Jaunes (#FFD700), Google Maps (#4285F4), LinkedIn (#0077B5), Manual (#6B7280)

2. **Table de liaison `prospects_sources`** (Many-to-Many) :
   - `prospect_id` (FK ‚Üí prospects.id)
   - `source_id` (FK ‚Üí sources_scraping.id)
   - `created_at` (DATETIME) - Date d'association
   - `updated_at` (DATETIME)
   - Cl√© primaire composite : (prospect_id, source_id)

3. **Modification table `prospects`** :
   - Suppression de la colonne `source_scraping`

**Backend** :

1. **Nouveau mod√®le Sequelize** :
   - `backend/src/models/SourceScraping.js` (nouveau)
   - Associations many-to-many configur√©es dans `models/index.js`

2. **Controllers mis √† jour** :
   - `scrapingController.js` :
     - Fonction `saveProspects()` r√©√©crite pour g√©rer sources multiples
     - D√©tection doublons par : nom+adresse, nom+GPS, email, URL
     - Ajout automatique de sources lors de doublons
     - Enrichissement automatique des donn√©es
   - `prospectController.js` :
     - Inclusion des sources dans toutes les r√©ponses API
     - Requ√™tes SQL optimis√©es pour filtrage par source
     - Support filtre source + tag simultan√©ment

**Frontend** :

1. **Nouveau composant** :
   - `frontend/src/components/SourceBadge.jsx` :
     - Affiche badges color√©s des sources
     - Tooltip avec date d'association
     - Adaptatif selon nombre de sources

2. **Composants modifi√©s** :
   - `ProspectList.jsx` : Nouvelle colonne "Sources" dans tableau
   - `ProspectCard.jsx` : Badges sources dans vue grille
   - `ProspectDetailsModal.jsx` : Section sources dans modal d√©tails

**Migration & Tests** :

1. **Script de migration** :
   - `backend/scripts/migrate-sources-scraping.js`
   - Idempotent, peut √™tre relanc√© sans risque
   - Migre automatiquement les donn√©es existantes

2. **Script de test** :
   - `backend/scripts/test-sources-multiples.js`
   - **6/6 tests passent** ‚úÖ
   - Teste cr√©ation, doublon, sources multiples, filtrage

**Fichiers cr√©√©s** :
- `backend/src/models/SourceScraping.js` (39 lignes)
- `backend/scripts/migrate-sources-scraping.js` (200 lignes)
- `backend/scripts/test-sources-multiples.js` (180 lignes)
- `frontend/src/components/SourceBadge.jsx` (24 lignes)
- `SOURCES_MULTIPLES.md` (documentation compl√®te, 450 lignes)

**Fichiers modifi√©s** :
- `backend/src/models/Prospect.js` (-8 lignes)
- `backend/src/models/index.js` (+18 lignes)
- `backend/src/controllers/scrapingController.js` (+142 lignes)
- `backend/src/controllers/prospectController.js` (+95 lignes)
- `frontend/src/components/ProspectList.jsx` (+4 lignes)
- `frontend/src/components/ProspectCard.jsx` (+3 lignes)
- `frontend/src/components/ProspectDetailsModal.jsx` (+8 lignes)

**B√©n√©fices utilisateur** :
- ‚úÖ Tra√ßabilit√© compl√®te de toutes les sources d'un prospect
- ‚úÖ Enrichissement progressif des donn√©es (chaque source apporte de nouvelles infos)
- ‚úÖ Aucune perte d'information lors de doublons
- ‚úÖ Filtrage par source fonctionnel
- ‚úÖ Interface visuelle claire avec badges color√©s
- ‚úÖ Performance optimis√©e avec requ√™tes SQL index√©es

**Documentation** :
- Guide complet dans `SOURCES_MULTIPLES.md`
- Exemples de requ√™tes SQL pour statistiques
- Workflow d√©taill√© du scraping avec sources multiples

---

## [Non versionn√©e] - 26 Novembre 2025

### ‚ú® Am√©liorations UX

#### Am√©lioration : Refonte de l'affichage de la liste des prospects
**Date** : 26 novembre 2025

**Objectif** : Am√©liorer la lisibilit√© et l'acc√®s aux informations des prospects dans l'interface.

**Modifications apport√©es** :

1. **Nouvelle organisation des colonnes du tableau** :
   - Nom de l'entreprise (cliquable en bleu)
   - Adresse
   - Code postal
   - Ville
   - T√©l√©phone
   - Tags

2. **Modal de d√©tails complets** :
   - Cr√©√© composant `ProspectDetailsModal.jsx`
   - Affiche toutes les informations du prospect :
     - Coordonn√©es compl√®tes (adresse, CP, ville, t√©l√©phone, email)
     - Informations compl√©mentaires (contact, poste, site web, LinkedIn)
     - Note/avis avec √©toile
     - Coordonn√©es GPS avec lien Google Maps
     - Tags avec gestion compl√®te
     - Source et date d'ajout
   - Design moderne avec layout en deux colonnes
   - Scroll interne si contenu long

3. **Interaction am√©lior√©e** :
   - Clic sur nom d'entreprise ouvre la modal
   - T√©l√©phone reste cliquable (appel direct)
   - Adresse tronqu√©e avec tooltip au survol
   - Tags directement modifiables depuis modal

**Fichiers cr√©√©s** :
- `frontend/src/components/ProspectDetailsModal.jsx` (236 lignes)

**Fichiers modifi√©s** :
- `frontend/src/components/ProspectList.jsx` (152 lignes, +84 insertions)

**B√©n√©fices utilisateur** :
- ‚úÖ Vision synth√©tique dans le tableau
- ‚úÖ Acc√®s rapide aux d√©tails complets
- ‚úÖ Mise en valeur des nouvelles donn√©es (ville, code postal)
- ‚úÖ Meilleure ergonomie mobile (modal responsive)
- ‚úÖ Toutes les infos accessibles en 1 clic

**Commit** : `dc7252a` feat(frontend): r√©organiser affichage prospects + modal d√©tails

---

### üêõ Corrections majeures

#### Correction : Extraction URL site web vs URL Google Maps
**Date** : 26 novembre 2025

**Sympt√¥me** : L'extraction Google Maps r√©cup√©rait l'URL du lieu sur Google Maps au lieu de l'URL du site web de l'entreprise.

**Exemple** :
- ‚ùå URL incorrecte : `https://www.google.com/maps/place/√âl√©gance+plomberie/data=!4m7!3m6!...`
- ‚úÖ URL correcte : `https://elegance-plombier.fr/`

**Cause racine** :
- Le s√©lecteur `a[href*="/maps/place/"]` r√©cup√©rait le lien Google Maps
- Ce lien √©tait ensuite copi√© dans le champ `url_site` (ligne 539)

**Solution** :
- Ajout de s√©lecteurs sp√©cifiques pour le site web :
  - `a[data-value="Site Web"]` (s√©lecteur principal)
  - `a[aria-label*="Visiter le site"]` (fallback 1)
  - `a[aria-label*="site web" i]` (fallback 2)
  - `a.lcr4fd[href]:not([href*="google.com"])` (fallback 3)
- S√©paration claire entre `url_maps` (Google Maps) et `url_site` (site web externe)
- Suppression du mapping incorrect `url_site = url_maps`

**Test de validation** :
- Script : `backend/scripts/test-google-maps-website-url.js`
- Recherche : "plombier" √† "Cannes"
- R√©sultat : ‚úÖ 100% (5/5 prospects avec URL site web correcte)

**Exemples d'URLs extraites** :
```
1. √âl√©gance plomberie ‚Üí https://elegance-plombier.fr/
2. Art Andr√© ‚Üí http://art-andre-depannage.fr/
3. Azur Service 06 ‚Üí https://www.azur-service06.fr/depannage-plomberie
4. Allo James ‚Üí http://plombier-cannes-allo-james.fr/
5. CL Plomberie ‚Üí https://www.cl-plomberie-cannes.fr/
```

**Fichiers modifi√©s** :
- `backend/src/services/googleMapsService.js` (lignes 530-548)

**Fichiers cr√©√©s** :
- `backend/scripts/test-google-maps-website-url.js` (nouveau test)

**Commit** : `4076b82` fix(google-maps): extraire URL site web au lieu URL Google Maps

---

#### Correction : T√©l√©phones extraits dans le champ adresse
**Date** : 26 novembre 2025

**Sympt√¥me** : Pour les prospects sans adresse physique sur Google Maps, le num√©ro de t√©l√©phone √©tait parfois extrait dans le champ `adresse` au lieu de rester √† `null`.

**Exemple** :
- ‚ùå Avant : `adresse='01 86 95 96 67'`, `telephone='01 86 95 96 67'`
- ‚úÖ Apr√®s : `adresse=null`, `telephone='01 86 95 96 67'`

**Cause racine** :
- L'algorithme de scoring des candidats d'adresse ne filtrait pas les num√©ros de t√©l√©phone
- Un texte contenant uniquement un t√©l√©phone pouvait obtenir un score positif s'il commen√ßait par un chiffre

**Solution** :
- Ajout d'une d√©tection de pattern t√©l√©phone AVANT le scoring d'adresse
- Skip automatique des √©l√©ments matchant le pattern t√©l√©phone fran√ßais
- Pattern utilis√© : `/\b0[1-9](?:[\s\.]?\d{2}){4}\b|\b\+33[\s\.]?[1-9](?:[\s\.]?\d{2}){4}\b/`

**Test de validation** :
- Script : `backend/scripts/test-adresse-vs-telephone.js`
- Recherche : "plombier" √† "Paris 15" (10 prospects)
- R√©sultat : ‚úÖ 100% de s√©paration correcte

**M√©triques** :
```
Total prospects: 10
‚úÖ Avec adresse valide (sans t√©l√©phone): 9/10 (90%)
‚úÖ Sans adresse (normal): 1/10 (10%)
‚ùå T√©l√©phone dans adresse: 0/10 (0%)
```

**Exemple de prospect corrig√©** :
- **Art Andr√©** : `adresse=null`, `telephone='01 86 95 96 67'` ‚úÖ

**Fichiers modifi√©s** :
- `backend/src/services/googleMapsService.js` (lignes 457-460)

**Fichiers cr√©√©s** :
- `backend/scripts/test-adresse-vs-telephone.js` (nouveau test)

**Commit** : `858c93d` fix(google-maps): emp√™cher t√©l√©phones d'√™tre extraits comme adresse

---

#### Probl√®me : Donn√©es manquantes en base de donn√©es (t√©l√©phone, URL, note, GPS)
**Sympt√¥me** : Lors du scraping Google Maps, seuls le nom et l'adresse √©taient sauvegard√©s en base de donn√©es, alors que t√©l√©phone, URL, note et coordonn√©es GPS √©taient bien extraits.

**Cause racine** :
1. Dans `googleMapsService.js` (lignes 546-547), les coordonn√©es GPS √©taient forc√©es √† `null` apr√®s extraction
2. Dans `scrapingController.js` (ligne 188-196), la fonction `saveProspects()` ne mappait pas les champs `telephone`, `latitude`, `longitude` et `note`
3. La regex d'extraction GPS utilisait le mauvais format (`@lat,lng` au lieu de `!3d...!4d...`)

**Solution** :
- ‚úÖ Supprim√© les lignes for√ßant GPS √† `null` dans `googleMapsService.js`
- ‚úÖ Ajout√© le mapping de `url_maps` vers `url_site` dans `googleMapsService.js`
- ‚úÖ Corrig√© la regex GPS pour supporter le format `!3d48.889609!4d2.344058` (prioritaire) avec fallback sur `@lat,lng`
- ‚úÖ Ajout√© les champs `telephone`, `latitude`, `longitude`, `note` dans `Prospect.create()` de `scrapingController.js`

**Fichiers modifi√©s** :
- `backend/src/services/googleMapsService.js` (lignes 521-564)
- `backend/src/controllers/scrapingController.js` (lignes 188-199)

**Test de validation** :
- Script : `backend/scripts/test-google-maps-extraction.js`
- R√©sultat : ‚úÖ 100% (3/3 prospects avec URL + note + GPS)
- Script : `backend/scripts/test-google-maps-telephone.js`
- R√©sultat : ‚úÖ 100% (5/5 √©lectriciens avec t√©l√©phone)

**M√©triques apr√®s correction** :
```
Boulangeries (3 prospects):
- Nom:       100% ‚úÖ
- Adresse:   100% ‚úÖ
- T√©l√©phone: 0% (normal, boulangeries n'affichent pas leur t√©l√©phone)
- URL:       100% ‚úÖ
- Note:      100% ‚úÖ
- GPS:       100% ‚úÖ

√âlectriciens (5 prospects):
- Nom:       100% ‚úÖ
- Adresse:   100% ‚úÖ
- T√©l√©phone: 100% ‚úÖ (5/5 avec num√©ro)
- URL:       100% ‚úÖ
- Note:      80% ‚úÖ (4/5)
- GPS:       100% ‚úÖ
```

---

#### Probl√®me : Encodage des accents dans les URLs de recherche
**Sympt√¥me** : Les recherches avec mots-cl√©s accentu√©s (ex: "√©lectricien", "√âvry") √©chouaient ou donnaient des r√©sultats incorrects √† cause de probl√®mes d'encodage URL.

**Cause racine** :
Les accents dans les mots-cl√©s n'√©taient pas normalis√©s avant d'√™tre utilis√©s dans les URLs de recherche, causant des probl√®mes d'encodage selon les navigateurs et les sites cibles.

**Solution** :
- ‚úÖ Cr√©√© module utilitaire `backend/src/utils/stringUtils.js` avec 3 fonctions :
  - `removeAccents(str)` : Retire tous les accents (utilise NFD + regex)
  - `normalizeKeyword(keyword)` : Normalise keyword + trim
  - `normalizeLocation(location)` : Normalise localisation + trim
- ‚úÖ Int√©gr√© la normalisation dans les 3 scrapers :
  - `googleMapsService.js` (ligne 30-43)
  - `pagesJaunesScraper.js` (ligne 271-284)
  - `linkedInScraper.js` (ligne 50-63)
- ‚úÖ Ajout√© logs informatifs quand normalisation effectu√©e

**Fichiers cr√©√©s** :
- `backend/src/utils/stringUtils.js` (63 lignes)

**Fichiers modifi√©s** :
- `backend/src/services/googleMapsService.js`
- `backend/src/services/scrapers/pagesJaunesScraper.js`
- `backend/src/services/scrapers/linkedInScraper.js`

**Tests de validation** :
- Script : `backend/scripts/test-accent-normalization.js`
- R√©sultat : ‚úÖ 18/18 tests pass√©s (100%)
- Exemples :
  - `"√©lectricien"` ‚Üí `"electricien"` ‚úÖ
  - `"√âvry"` ‚Üí `"Evry"` ‚úÖ
  - `"Saint-√âtienne"` ‚Üí `"Saint-Etienne"` ‚úÖ
  - `"Cr√©teil"` ‚Üí `"Creteil"` ‚úÖ

- Script : `backend/scripts/test-scraping-avec-accents.js`
- R√©sultat : ‚úÖ Normalisation automatique confirm√©e lors du scraping r√©el
- Log exemple :
  ```
  [GoogleMapsService] Normalisation des accents:
    Keyword: "√©lectricien" ‚Üí "electricien"
    Location: "√âvry" ‚Üí "Evry"
  [GoogleMapsService] Recherche: "electricien" √† "Evry"
  ```

---

### üìä Impact global

**Avant** :
- ‚ùå T√©l√©phones extraits mais non sauvegard√©s
- ‚ùå URLs extraites mais non sauvegard√©es
- ‚ùå Notes extraites mais non sauvegard√©es
- ‚ùå Coordonn√©es GPS jamais extraites
- ‚ùå Recherches avec accents √©chouaient

**Apr√®s** :
- ‚úÖ 100% des t√©l√©phones sauvegard√©s (quand visibles)
- ‚úÖ 100% des URLs sauvegard√©es
- ‚úÖ 100% des notes sauvegard√©es (quand disponibles)
- ‚úÖ 100% des coordonn√©es GPS sauvegard√©es
- ‚úÖ Accents normalis√©s automatiquement dans tous les scrapers

**Taux de compl√©tude des donn√©es** : **0-50% ‚Üí 90-100%** üéâ

---

### üß™ Scripts de test ajout√©s

1. `backend/scripts/test-google-maps-extraction.js` - Test extraction compl√®te avec sauvegarde
2. `backend/scripts/test-google-maps-telephone.js` - Test sp√©cifique t√©l√©phones (√©lectriciens)
3. `backend/scripts/test-accent-normalization.js` - Test normalisation accents (18 tests)
4. `backend/scripts/test-scraping-avec-accents.js` - Test int√©gration normalisation

---

### üìù Documentation

- Tous les changements sont document√©s inline dans le code
- Logs de debug am√©lior√©s pour faciliter le troubleshooting
- Scripts de test comment√©s et pr√™ts √† √™tre relanc√©s

---

**Date** : 26 novembre 2025
**Auteur** : Claude Code + Yannick Murat
**Statut** : ‚úÖ Valid√© et test√©
