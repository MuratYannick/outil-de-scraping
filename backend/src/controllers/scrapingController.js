import taskManager from '../services/taskManager.js';
import { PagesJaunesScraper } from '../services/scrapers/pagesJaunesScraper.js';
import { getGoogleMapsService } from '../services/googleMapsService.js';
import { getLinkedInScraper } from '../services/scrapers/linkedInScraper.js';
import prospectSaveService from '../services/prospectSaveService.js';

/**
 * @route   POST /api/scraping/lancer
 * @desc    Lancer une tÃ¢che de scraping asynchrone
 * @access  Public
 */
export const lancerScraping = async (req, res) => {
  try {
    const { keyword, location, source = 'Pages Jaunes', startPage = 1, maxPages = 1, maxResults = 10, excludeDuplicates = false } = req.body;

    // Validation des paramÃ¨tres
    if (!keyword || !location) {
      return res.status(400).json({
        error: 'Bad Request',
        message: 'Les paramÃ¨tres "keyword" et "location" sont requis',
      });
    }

    // CrÃ©er une tÃ¢che
    const task = taskManager.createTask({
      keyword,
      location,
      source,
      startPage,
      maxPages,
      maxResults,
      excludeDuplicates,
    });

    // Lancer le scraping de maniÃ¨re asynchrone
    scrapeAsync(task.id, keyword, location, { startPage, maxPages, maxResults, source, excludeDuplicates });

    // Retourner immÃ©diatement l'ID de la tÃ¢che
    res.status(202).json({
      task_id: task.id,
      status: task.status,
      message: 'TÃ¢che de scraping crÃ©Ã©e et lancÃ©e',
      params: {
        keyword,
        location,
        source,
        maxPages,
        maxResults,
      },
    });
  } catch (error) {
    console.error('Error launching scraping:', error);
    res.status(500).json({
      error: 'Internal Server Error',
      message: error.message,
    });
  }
};

/**
 * Fonction asynchrone pour effectuer le scraping
 * @param {string} taskId - ID de la tÃ¢che
 * @param {string} keyword - Mot-clÃ© de recherche
 * @param {string} location - Localisation
 * @param {Object} options - Options de scraping
 */
async function scrapeAsync(taskId, keyword, location, options = {}) {
  try {
    // Mettre Ã  jour le statut Ã  "in_progress"
    taskManager.updateTaskStatus(taskId, 'in_progress');

    const { source = 'Pages Jaunes', startPage = 1, maxPages = 1, maxResults = 10, excludeDuplicates = false } = options;
    let prospects = [];
    let scrapingResult = null; // Stocker le rÃ©sultat complet du scraping

    // CrÃ©er une fonction de vÃ©rification de doublons en temps rÃ©el
    const isDuplicate = excludeDuplicates ? async (prospectData) => {
      // VÃ©rifier d'abord par email ou URL (exact match)
      const existingExact = await Prospect.findOne({
        where: {
          [Op.or]: [
            prospectData.email ? { email: prospectData.email } : null,
            prospectData.url_site ? { url_site: prospectData.url_site } : null,
          ].filter(Boolean),
        },
      });

      if (existingExact) return true;

      // VÃ©rifier par nom + adresse avec normalisation
      if (prospectData.nom_entreprise && prospectData.adresse) {
        const potentialDuplicates = await Prospect.findAll({
          where: {
            nom_entreprise: prospectData.nom_entreprise
          }
        });

        // Comparer les adresses normalisÃ©es
        for (const candidate of potentialDuplicates) {
          if (candidate.adresse && addressesMatch(prospectData.adresse, candidate.adresse)) {
            return true;
          }
        }
      }

      return false;
    } : null;

    // Choisir le scraper appropriÃ© selon la source
    if (source === 'Google Maps') {
      // Utiliser le service Google Maps (scraper ou API selon config)
      const googleMapsService = getGoogleMapsService();

      prospects = await googleMapsService.search(
        { keyword, location, maxResults },
        (progress, message) => {
          taskManager.updateTaskProgress(taskId, progress, { message });
        }
      );

    } else if (source === 'LinkedIn') {
      // LinkedIn (Mode Public - LimitÃ©)
      const linkedInScraper = getLinkedInScraper();

      console.log(`[ScrapingController] ðŸ“Š LinkedIn scraping - Mode Public`);
      console.log(`[ScrapingController] âš ï¸ Limites : Max ${Math.min(maxResults, 10)} profils, dÃ©lais longs`);

      prospects = await linkedInScraper.scrape(keyword, location, {
        maxResults: Math.min(maxResults, 10), // Forcer limite de 10 max
        onProgress: (data) => {
          taskManager.updateTaskProgress(taskId, data.progress, {
            message: data.message,
            step: data.step
          });
        },
      });

      // LinkedIn retourne directement un tableau de prospects (pas de result wrapper)
      // Pas besoin de transformation

    } else {
      // Pages Jaunes (par dÃ©faut)
      const scraper = new PagesJaunesScraper();

      console.log(`[ScrapingController] Mode excludeDuplicates: ${excludeDuplicates ? 'OUI' : 'NON'}`);

      scrapingResult = await scraper.scrape(keyword, location, {
        startPage,
        maxPages,
        maxResults,
        excludeDuplicates,
        isDuplicate, // Callback pour vÃ©rifier les doublons en temps rÃ©el
        onProgress: (progress, data) => {
          taskManager.updateTaskProgress(taskId, progress, data);
        },
      });

      prospects = scrapingResult.prospects;
    }

    // Sauvegarder les prospects en base de donnÃ©es avec leur source
    const savedProspects = await saveProspects(prospects, keyword, source);

    // PrÃ©parer les donnÃ©es de rÃ©sultat selon la source
    let taskResult = {
      prospects: savedProspects,
      total: savedProspects.length,
      duplicates_skipped: prospects.length - savedProspects.length,
    };

    // Ajouter des mÃ©triques spÃ©cifiques selon la source
    if (source === 'LinkedIn') {
      taskResult.source = 'LinkedIn (Mode Public)';
      taskResult.captcha_detected = getLinkedInScraper().captchaDetected;
      taskResult.success = savedProspects.length > 0;
    } else if (source === 'Google Maps') {
      taskResult.source = 'Google Maps';
      taskResult.success = true;
    } else {
      // Pages Jaunes
      taskResult.pages_scraped = scrapingResult?.pages_scraped || 1;
      taskResult.success = scrapingResult?.success || false;
    }

    // Marquer la tÃ¢che comme terminÃ©e
    taskManager.completeTask(taskId, taskResult);

    console.log(`[ScrapingController] TÃ¢che ${taskId} terminÃ©e: ${savedProspects.length} prospects sauvegardÃ©s`);
  } catch (error) {
    console.error(`[ScrapingController] Erreur tÃ¢che ${taskId}:`, error);
    taskManager.failTask(taskId, error);
  }
}

/**
 * Sauvegarder les prospects en base de donnÃ©es avec gestion des sources multiples
 * GÃ¨re les doublons et l'enrichissement automatique
 * @param {Array} prospects - Liste des prospects Ã  sauvegarder
 * @param {string} keyword - Mot-clÃ© pour crÃ©er un tag
 * @param {string} sourceName - Nom de la source de scraping (ex: 'Google Maps', 'Pages Jaunes')
 * @returns {Array} Prospects sauvegardÃ©s
 */
/**
 * Sauvegarde les prospects en utilisant le service dÃ©diÃ©
 * @deprecated Utiliser directement prospectSaveService.saveProspects()
 * @private
 */
async function saveProspects(prospects, keyword, sourceName) {
  return await prospectSaveService.saveProspects(prospects, keyword, sourceName);
}

/**
 * @route   GET /api/scraping/status/:task_id
 * @desc    RÃ©cupÃ©rer le statut d'une tÃ¢che de scraping
 * @access  Public
 */
export const getScrapingStatus = async (req, res) => {
  try {
    const { task_id } = req.params;

    const task = taskManager.getTask(task_id);

    if (!task) {
      return res.status(404).json({
        error: 'Not Found',
        message: `TÃ¢che non trouvÃ©e: ${task_id}`,
      });
    }

    res.json({
      task_id: task.id,
      status: task.status,
      progress: task.progress,
      params: task.params,
      results: {
        total: task.results.total,
        pages_scraped: task.results.pages_scraped,
        errors: task.results.errors,
      },
      createdAt: task.createdAt,
      startedAt: task.startedAt,
      completedAt: task.completedAt,
      error: task.error,
    });
  } catch (error) {
    console.error('Error getting scraping status:', error);
    res.status(500).json({
      error: 'Internal Server Error',
      message: error.message,
    });
  }
};

/**
 * @route   POST /api/scraping/cancel/:task_id
 * @desc    Annuler une tÃ¢che de scraping en cours
 * @access  Public
 */
export const cancelScraping = async (req, res) => {
  try {
    const { task_id } = req.params;

    const cancelled = taskManager.cancelTask(task_id);

    if (!cancelled) {
      return res.status(400).json({
        error: 'Bad Request',
        message: 'Impossible d\'annuler cette tÃ¢che (non trouvÃ©e ou dÃ©jÃ  terminÃ©e)',
      });
    }

    res.json({
      task_id,
      status: 'cancelled',
      message: 'TÃ¢che annulÃ©e avec succÃ¨s',
    });
  } catch (error) {
    console.error('Error cancelling scraping:', error);
    res.status(500).json({
      error: 'Internal Server Error',
      message: error.message,
    });
  }
};

/**
 * @route   GET /api/scraping/tasks
 * @desc    RÃ©cupÃ©rer toutes les tÃ¢ches de scraping
 * @access  Public
 */
export const getAllTasks = async (req, res) => {
  try {
    const { status, limit = 20 } = req.query;

    const tasks = taskManager.getAllTasks({
      status,
      limit: parseInt(limit),
    });

    res.json({
      data: tasks,
      total: tasks.length,
    });
  } catch (error) {
    console.error('Error getting all tasks:', error);
    res.status(500).json({
      error: 'Internal Server Error',
      message: error.message,
    });
  }
};

/**
 * @route   GET /api/scraping/stats
 * @desc    RÃ©cupÃ©rer les statistiques du gestionnaire de tÃ¢ches
 * @access  Public
 */
export const getScrapingStats = async (req, res) => {
  try {
    const stats = taskManager.getStats();

    res.json(stats);
  } catch (error) {
    console.error('Error getting scraping stats:', error);
    res.status(500).json({
      error: 'Internal Server Error',
      message: error.message,
    });
  }
};
